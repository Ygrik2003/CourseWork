{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HYPER-PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df : pd.DataFrame):\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if str(col_type)[:5] == 'float':\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if c_min > np.finfo('f2').min and c_max < np.finfo('f2').max:\n",
    "                df[col] = df[col].astype(np.float16)\n",
    "            elif c_min > np.finfo('f4').min and c_max < np.finfo('f4').max:\n",
    "                df[col] = df[col].astype(np.float32)\n",
    "            else:\n",
    "                df[col] = df[col].astype(np.float64)\n",
    "        elif str(col_type)[:3] == 'int':\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if c_min > np.iinfo('i1').min and c_max < np.iinfo('i1').max:\n",
    "                df[col] = df[col].astype(np.int8)\n",
    "            elif c_min > np.iinfo('i2').min and c_max < np.iinfo('i2').max:\n",
    "                df[col] = df[col].astype(np.int16)\n",
    "            elif c_min > np.iinfo('i4').min and c_max < np.iinfo('i4').max:\n",
    "                df[col] = df[col].astype(np.int32)\n",
    "            elif c_min > np.iinfo('i8').min and c_max < np.iinfo('i8').max:\n",
    "                df[col] = df[col].astype(np.int64)\n",
    "        elif str(col_type)[:8] == 'datetime':\n",
    "            df[col] = df[col].astype('category')\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    print('Потребление памяти меньше на',\n",
    "         round(start_mem - end_mem, 2),\n",
    "         'Мб (минус',\n",
    "         round(100 * (start_mem - end_mem) / start_mem, 1),\n",
    "         '%)')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = {\n",
    "    \"SHG Intensity\" : [\n",
    "        \"SHG Intensity Mean\",\n",
    "        \"SHG Intensity MAD\",\n",
    "        \"SHG Intensity Contrast\",\n",
    "        \"SHG Intensity Correlation\",\n",
    "        \"SHG Intensity Entropy\",\n",
    "        \"SHG Intensity ASM\",\n",
    "        \"SHG Intensity IDM\"\n",
    "    ],\n",
    "    \"R-Ratio\" : [\n",
    "        \"R-Ratio Mean\",\n",
    "        \"R-Ratio MAD\",\n",
    "        \"R-Ratio Contrast\",\n",
    "        \"R-Ratio Correlation\",\n",
    "        \"R-Ratio Entropy\",\n",
    "        \"R-Ratio ASM\"\n",
    "    ],\n",
    "    \"Degree of Circular Polarization\" : [\n",
    "        \"Degree of Circular Polarization Mean\",\n",
    "        \"Degree of Circular Polarization MAD\",\n",
    "        \"Degree of Circular Polarization Contrast\",\n",
    "        \"Degree of Circular Polarization Correlation\",\n",
    "        \"Degree of Circular Polarization Entropy\",\n",
    "        \"Degree of Circular Polarization ASM\",\n",
    "        \"Degree of Circular Polarization IDM\"\n",
    "    ],\n",
    "    \"SHG-CD\" : [ \n",
    "        \"SHG-CD MAD\",\n",
    "        \"SHG-CD Contrast\",\n",
    "        \"SHG-CD Correlation\",\n",
    "        \"SHG-CD Entropy\",\n",
    "        \"SHG-CD ASM\",\n",
    "        \"SHG-CD IDM\"\n",
    "    ],\n",
    "    \"SHG-LD\" : [\n",
    "        \"SHG-LD MAD\",\n",
    "        \"SHG-LD Contrast\",\n",
    "        \"SHG-LD Correlation\",\n",
    "        \"SHG-LD Entropy\",\n",
    "        \"SHG-LD ASM\",\n",
    "        \"SHG-LD IDM\"\n",
    "    ],\n",
    "    \"Params\" : [\n",
    "        \"2-Group Tag\",\n",
    "        \"Pixel Density\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "x_axis = sum([methods[key] for key in methods.keys() if key != \"Params\"], [])\n",
    "# x_axis += [methods['Params'][1]]\n",
    "y_axis = methods[\"Params\"][0]\n",
    "def getData(table_number):\n",
    "    data = pd.read_excel(io=\"../../Data/41598_2022_13623_MOESM3_ESM.xlsx\", \n",
    "    sheet_name=f\"{1 << 2 * (table_number - 1)} Subimage Training\")\n",
    "    data = reduce_mem_usage(data)\n",
    "    data = (data - data.min()) / (data.max() - data.min())\n",
    "    #data[\"2-Group Tag\"] = data[y_axis] == 2\n",
    "    return data[x_axis].to_numpy(), data[y_axis].to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Потребление памяти меньше на 0.69 Мб (минус 75.4 %)\n"
     ]
    }
   ],
   "source": [
    "X_data, y_data = getData(5)\n",
    "n_samples, n_features, batch_size, num_steps = *X_data.shape, 100, 20000\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "X = tf.compat.v1.placeholder(tf.float32, shape=(batch_size, n_feauters))\n",
    "y = tf.compat.v1.placeholder(tf.float32, shape=(batch_size,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.compat.v1.variable_scope('linear-regression'):\n",
    "    k = tf.compat.v1.Variable(X_data[0].astype(np.float32).reshape((n_features, 1)), name='coef')\n",
    "    b = tf.compat.v1.Variable(tf.zeros((1,)), name='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tf.matmul(X, k) + b\n",
    "loss = tf.reduce_sum( tf.keras.losses.BinaryCrossentropy(from_logits=True)(y, y_pred) )\n",
    "accuracy = tf.reduce_mean( tf.cast( tf.equal( tf.math.round(y_pred), y ), tf.float32) )\n",
    "optimizer = tf.compat.v1.train.GradientDescentOptimizer(learning_rate=0.1).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха acc:12.780000269412994%,  1000: 0.3707754909992218, b = [0.19009428]\n",
      "Эпоха acc:10.559999942779541%,  2000: 0.27445918321609497, b = [0.25989044]\n",
      "Эпоха acc:10.360000282526016%,  3000: 0.20695272088050842, b = [0.17563729]\n",
      "Эпоха acc:7.14000016450882%,  4000: 0.25611811876296997, b = [0.06005829]\n",
      "Эпоха acc:6.840000301599503%,  5000: 0.2621059715747833, b = [-0.08655767]\n",
      "Эпоха acc:8.299999684095383%,  6000: 0.16319236159324646, b = [-0.23842528]\n",
      "Эпоха acc:10.14000028371811%,  7000: 0.2120329886674881, b = [-0.3781189]\n",
      "Эпоха acc:9.920000284910202%,  8000: 0.232200026512146, b = [-0.53261805]\n",
      "Эпоха acc:7.999999821186066%,  9000: 0.23521655797958374, b = [-0.68587625]\n",
      "Эпоха acc:8.550000190734863%,  10000: 0.27598345279693604, b = [-0.81811714]\n",
      "Эпоха acc:8.51999968290329%,  11000: 0.2520977854728699, b = [-0.9481614]\n",
      "Эпоха acc:3.9000000804662704%,  12000: 0.26019415259361267, b = [-1.076103]\n",
      "Эпоха acc:7.360000163316727%,  13000: 0.263037770986557, b = [-1.1859249]\n",
      "Эпоха acc:7.039999961853027%,  14000: 0.26007339358329773, b = [-1.3008242]\n",
      "Эпоха acc:8.51999968290329%,  15000: 0.24619899690151215, b = [-1.390513]\n",
      "Эпоха acc:4.1999999433755875%,  16000: 0.1782023310661316, b = [-1.521174]\n",
      "Эпоха acc:10.96000000834465%,  17000: 0.2768770158290863, b = [-1.6159601]\n",
      "Эпоха acc:8.420000225305557%,  18000: 0.19978569447994232, b = [-1.7138852]\n",
      "Эпоха acc:7.079999893903732%,  19000: 0.24125657975673676, b = [-1.7890133]\n",
      "Эпоха acc:6.560000032186508%,  20000: 0.25711026787757874, b = [-1.8776872]\n"
     ]
    }
   ],
   "source": [
    "display_step = 1000\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    sess.run(tf.compat.v1.initialize_all_variables())\n",
    "    for i in range(num_steps):\n",
    "        #print(sess.run([b]))\n",
    "        indices = np.random.choice(n_samples, batch_size)\n",
    "        X_batch, y_batch = X_data[indices], y_data[indices]\n",
    "#         print(X_batch[0])\n",
    "#         break\n",
    "        _, loss_val, k_val, b_val, accuracy_ = sess.run([optimizer, loss, k, b, accuracy], feed_dict = {X : X_batch, y: y_batch})\n",
    "        if (i + 1) % display_step == 0:\n",
    "            print(f'Эпоха acc:{accuracy_*100}%,  {i + 1}: {loss_val}, b = {b_val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "deb4792152b8b9767403eeef0a1b0f34b83d442136ccee9184cd7d1131f09aa0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

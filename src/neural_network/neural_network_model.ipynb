{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Activation\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HYPER-PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df : pd.DataFrame):\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if str(col_type)[:5] == 'float':\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if c_min > np.finfo('f2').min and c_max < np.finfo('f2').max:\n",
    "                df[col] = df[col].astype(np.float16)\n",
    "            elif c_min > np.finfo('f4').min and c_max < np.finfo('f4').max:\n",
    "                df[col] = df[col].astype(np.float32)\n",
    "            else:\n",
    "                df[col] = df[col].astype(np.float64)\n",
    "        elif str(col_type)[:3] == 'int':\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if c_min > np.iinfo('i1').min and c_max < np.iinfo('i1').max:\n",
    "                df[col] = df[col].astype(np.int8)\n",
    "            elif c_min > np.iinfo('i2').min and c_max < np.iinfo('i2').max:\n",
    "                df[col] = df[col].astype(np.int16)\n",
    "            elif c_min > np.iinfo('i4').min and c_max < np.iinfo('i4').max:\n",
    "                df[col] = df[col].astype(np.int32)\n",
    "            elif c_min > np.iinfo('i8').min and c_max < np.iinfo('i8').max:\n",
    "                df[col] = df[col].astype(np.int64)\n",
    "        elif str(col_type)[:8] == 'datetime':\n",
    "            df[col] = df[col].astype('category')\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    print('Потребление памяти меньше на',\n",
    "         round(start_mem - end_mem, 2),\n",
    "         'Мб (минус',\n",
    "         round(100 * (start_mem - end_mem) / start_mem, 1),\n",
    "         '%)')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = {\n",
    "    \"SHG Intensity\" : [\n",
    "        \"SHG Intensity Mean\",\n",
    "        \"SHG Intensity MAD\",\n",
    "        \"SHG Intensity Contrast\",\n",
    "        \"SHG Intensity Correlation\",\n",
    "        \"SHG Intensity Entropy\",\n",
    "        \"SHG Intensity ASM\",\n",
    "        \"SHG Intensity IDM\"\n",
    "    ],\n",
    "    \"R-Ratio\" : [\n",
    "        \"R-Ratio Mean\",\n",
    "        \"R-Ratio MAD\",\n",
    "        \"R-Ratio Contrast\",\n",
    "        \"R-Ratio Correlation\",\n",
    "        \"R-Ratio Entropy\",\n",
    "        \"R-Ratio ASM\"\n",
    "    ],\n",
    "    \"Degree of Circular Polarization\" : [\n",
    "        \"Degree of Circular Polarization Mean\",\n",
    "        \"Degree of Circular Polarization MAD\",\n",
    "        \"Degree of Circular Polarization Contrast\",\n",
    "        \"Degree of Circular Polarization Correlation\",\n",
    "        \"Degree of Circular Polarization Entropy\",\n",
    "        \"Degree of Circular Polarization ASM\",\n",
    "        \"Degree of Circular Polarization IDM\"\n",
    "    ],\n",
    "    \"SHG-CD\" : [ \n",
    "        \"SHG-CD MAD\",\n",
    "        \"SHG-CD Contrast\",\n",
    "        \"SHG-CD Correlation\",\n",
    "        \"SHG-CD Entropy\",\n",
    "        \"SHG-CD ASM\",\n",
    "        \"SHG-CD IDM\"\n",
    "    ],\n",
    "    \"SHG-LD\" : [\n",
    "        \"SHG-LD MAD\",\n",
    "        \"SHG-LD Contrast\",\n",
    "        \"SHG-LD Correlation\",\n",
    "        \"SHG-LD Entropy\",\n",
    "        \"SHG-LD ASM\",\n",
    "        \"SHG-LD IDM\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "x_axis = sum([methods[key] for key in methods.keys()], [])\n",
    "# x_axis += \"Pixel Density\"\n",
    "\n",
    "y_axis = \"2-Group Tag\"\n",
    "\n",
    "def getData(table_number):\n",
    "    data = pd.read_excel(io=\"../../Data/41598_2022_13623_MOESM3_ESM.xlsx\", \n",
    "    sheet_name=f\"{1 << 2 * (table_number - 1)} Subimage Training\")\n",
    "    data = reduce_mem_usage(data)\n",
    "    data = (data - data.min()) / (data.max() - data.min())\n",
    "    #data[\"2-Group Tag\"] = data[y_axis] == 2\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Потребление памяти меньше на 0.24 Мб (минус 75.3 %)\n"
     ]
    }
   ],
   "source": [
    "data = getData(4)\n",
    "\n",
    "train_data = data.sample(frac=0.8, random_state=0)\n",
    "test_data = data.drop(train_data.index)\n",
    "X_train, X_test = train_data[x_axis].to_numpy(), test_data[x_axis].to_numpy()\n",
    "y_train, y_test = train_data[y_axis].to_numpy(), test_data[y_axis].to_numpy()\n",
    "\n",
    "X_train_data_true = X_train[y_train == 1]\n",
    "X_train_data_false = X_train[y_train == 0]\n",
    "\n",
    "n_samples, n_features, batch_size = *X_train.shape, 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(963, 32) (963,)\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 32ms/step - loss: 0.7402 - accuracy: 0.5171 - val_loss: 0.7404 - val_accuracy: 0.5062\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.7351 - accuracy: 0.5213 - val_loss: 0.7345 - val_accuracy: 0.4979\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.7304 - accuracy: 0.5234 - val_loss: 0.7296 - val_accuracy: 0.4979\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.7263 - accuracy: 0.5306 - val_loss: 0.7251 - val_accuracy: 0.5021\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.7226 - accuracy: 0.5348 - val_loss: 0.7209 - val_accuracy: 0.5104\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.7188 - accuracy: 0.5400 - val_loss: 0.7171 - val_accuracy: 0.5062\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.7154 - accuracy: 0.5410 - val_loss: 0.7138 - val_accuracy: 0.5104\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.7122 - accuracy: 0.5421 - val_loss: 0.7104 - val_accuracy: 0.5021\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.7091 - accuracy: 0.5462 - val_loss: 0.7073 - val_accuracy: 0.5021\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.7061 - accuracy: 0.5504 - val_loss: 0.7042 - val_accuracy: 0.5187\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.7031 - accuracy: 0.5524 - val_loss: 0.7011 - val_accuracy: 0.5228\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.7001 - accuracy: 0.5566 - val_loss: 0.6981 - val_accuracy: 0.5228\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6973 - accuracy: 0.5587 - val_loss: 0.6953 - val_accuracy: 0.5311\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6944 - accuracy: 0.5722 - val_loss: 0.6927 - val_accuracy: 0.5311\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6917 - accuracy: 0.5742 - val_loss: 0.6900 - val_accuracy: 0.5353\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6889 - accuracy: 0.5753 - val_loss: 0.6872 - val_accuracy: 0.5436\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6862 - accuracy: 0.5794 - val_loss: 0.6847 - val_accuracy: 0.5519\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6835 - accuracy: 0.5836 - val_loss: 0.6821 - val_accuracy: 0.5643\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6807 - accuracy: 0.5846 - val_loss: 0.6795 - val_accuracy: 0.5726\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6781 - accuracy: 0.5877 - val_loss: 0.6771 - val_accuracy: 0.5809\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6754 - accuracy: 0.5888 - val_loss: 0.6745 - val_accuracy: 0.5851\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6728 - accuracy: 0.5940 - val_loss: 0.6720 - val_accuracy: 0.5892\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6702 - accuracy: 0.5961 - val_loss: 0.6696 - val_accuracy: 0.5892\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6676 - accuracy: 0.5981 - val_loss: 0.6671 - val_accuracy: 0.5934\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6651 - accuracy: 0.6002 - val_loss: 0.6647 - val_accuracy: 0.5934\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6626 - accuracy: 0.6033 - val_loss: 0.6623 - val_accuracy: 0.5975\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6601 - accuracy: 0.6096 - val_loss: 0.6598 - val_accuracy: 0.5975\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6577 - accuracy: 0.6168 - val_loss: 0.6576 - val_accuracy: 0.5975\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6552 - accuracy: 0.6158 - val_loss: 0.6552 - val_accuracy: 0.5975\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6527 - accuracy: 0.6231 - val_loss: 0.6529 - val_accuracy: 0.6017\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6504 - accuracy: 0.6262 - val_loss: 0.6507 - val_accuracy: 0.6017\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6480 - accuracy: 0.6282 - val_loss: 0.6484 - val_accuracy: 0.6100\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6455 - accuracy: 0.6345 - val_loss: 0.6462 - val_accuracy: 0.6100\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6432 - accuracy: 0.6386 - val_loss: 0.6439 - val_accuracy: 0.6224\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6409 - accuracy: 0.6480 - val_loss: 0.6417 - val_accuracy: 0.6266\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6386 - accuracy: 0.6563 - val_loss: 0.6396 - val_accuracy: 0.6266\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6363 - accuracy: 0.6594 - val_loss: 0.6376 - val_accuracy: 0.6266\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6340 - accuracy: 0.6584 - val_loss: 0.6355 - val_accuracy: 0.6307\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6318 - accuracy: 0.6604 - val_loss: 0.6334 - val_accuracy: 0.6307\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6296 - accuracy: 0.6677 - val_loss: 0.6313 - val_accuracy: 0.6349\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6274 - accuracy: 0.6739 - val_loss: 0.6291 - val_accuracy: 0.6432\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6252 - accuracy: 0.6750 - val_loss: 0.6271 - val_accuracy: 0.6473\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6230 - accuracy: 0.6812 - val_loss: 0.6251 - val_accuracy: 0.6432\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6208 - accuracy: 0.6854 - val_loss: 0.6231 - val_accuracy: 0.6473\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6187 - accuracy: 0.6854 - val_loss: 0.6211 - val_accuracy: 0.6473\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6165 - accuracy: 0.6926 - val_loss: 0.6190 - val_accuracy: 0.6598\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6145 - accuracy: 0.6937 - val_loss: 0.6170 - val_accuracy: 0.6639\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6123 - accuracy: 0.6968 - val_loss: 0.6151 - val_accuracy: 0.6722\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6104 - accuracy: 0.7020 - val_loss: 0.6132 - val_accuracy: 0.6722\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6082 - accuracy: 0.7009 - val_loss: 0.6113 - val_accuracy: 0.6805\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6062 - accuracy: 0.7020 - val_loss: 0.6094 - val_accuracy: 0.6763\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6042 - accuracy: 0.7040 - val_loss: 0.6075 - val_accuracy: 0.6846\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6022 - accuracy: 0.7051 - val_loss: 0.6056 - val_accuracy: 0.6888\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6002 - accuracy: 0.7051 - val_loss: 0.6038 - val_accuracy: 0.6888\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5983 - accuracy: 0.7092 - val_loss: 0.6020 - val_accuracy: 0.6929\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5963 - accuracy: 0.7082 - val_loss: 0.6002 - val_accuracy: 0.6929\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5944 - accuracy: 0.7092 - val_loss: 0.5985 - val_accuracy: 0.6888\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5925 - accuracy: 0.7082 - val_loss: 0.5967 - val_accuracy: 0.6888\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5906 - accuracy: 0.7124 - val_loss: 0.5949 - val_accuracy: 0.7054\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5887 - accuracy: 0.7155 - val_loss: 0.5931 - val_accuracy: 0.7137\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5868 - accuracy: 0.7196 - val_loss: 0.5913 - val_accuracy: 0.7095\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5850 - accuracy: 0.7217 - val_loss: 0.5896 - val_accuracy: 0.7095\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5832 - accuracy: 0.7238 - val_loss: 0.5878 - val_accuracy: 0.7178\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5814 - accuracy: 0.7269 - val_loss: 0.5861 - val_accuracy: 0.7220\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5795 - accuracy: 0.7279 - val_loss: 0.5844 - val_accuracy: 0.7261\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5778 - accuracy: 0.7373 - val_loss: 0.5826 - val_accuracy: 0.7344\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5760 - accuracy: 0.7383 - val_loss: 0.5810 - val_accuracy: 0.7386\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5743 - accuracy: 0.7373 - val_loss: 0.5793 - val_accuracy: 0.7427\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5724 - accuracy: 0.7445 - val_loss: 0.5776 - val_accuracy: 0.7427\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5707 - accuracy: 0.7466 - val_loss: 0.5760 - val_accuracy: 0.7427\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5690 - accuracy: 0.7466 - val_loss: 0.5744 - val_accuracy: 0.7469\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5673 - accuracy: 0.7487 - val_loss: 0.5727 - val_accuracy: 0.7510\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5656 - accuracy: 0.7591 - val_loss: 0.5713 - val_accuracy: 0.7510\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5639 - accuracy: 0.7591 - val_loss: 0.5697 - val_accuracy: 0.7510\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5623 - accuracy: 0.7612 - val_loss: 0.5682 - val_accuracy: 0.7593\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5606 - accuracy: 0.7632 - val_loss: 0.5666 - val_accuracy: 0.7635\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5590 - accuracy: 0.7705 - val_loss: 0.5651 - val_accuracy: 0.7676\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5574 - accuracy: 0.7674 - val_loss: 0.5636 - val_accuracy: 0.7676\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5558 - accuracy: 0.7747 - val_loss: 0.5621 - val_accuracy: 0.7718\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5542 - accuracy: 0.7767 - val_loss: 0.5606 - val_accuracy: 0.7801\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5526 - accuracy: 0.7809 - val_loss: 0.5591 - val_accuracy: 0.7842\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5510 - accuracy: 0.7830 - val_loss: 0.5577 - val_accuracy: 0.7842\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5494 - accuracy: 0.7830 - val_loss: 0.5562 - val_accuracy: 0.7842\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5479 - accuracy: 0.7861 - val_loss: 0.5547 - val_accuracy: 0.7842\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5463 - accuracy: 0.7871 - val_loss: 0.5533 - val_accuracy: 0.7884\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5448 - accuracy: 0.7902 - val_loss: 0.5519 - val_accuracy: 0.7884\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5433 - accuracy: 0.7913 - val_loss: 0.5505 - val_accuracy: 0.7884\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5419 - accuracy: 0.7902 - val_loss: 0.5491 - val_accuracy: 0.7884\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5403 - accuracy: 0.7954 - val_loss: 0.5477 - val_accuracy: 0.7884\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5389 - accuracy: 0.7934 - val_loss: 0.5463 - val_accuracy: 0.7925\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5374 - accuracy: 0.7954 - val_loss: 0.5449 - val_accuracy: 0.7925\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5359 - accuracy: 0.7985 - val_loss: 0.5436 - val_accuracy: 0.7925\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5344 - accuracy: 0.8027 - val_loss: 0.5422 - val_accuracy: 0.7925\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5331 - accuracy: 0.8006 - val_loss: 0.5409 - val_accuracy: 0.7925\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5316 - accuracy: 0.8058 - val_loss: 0.5396 - val_accuracy: 0.7967\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5302 - accuracy: 0.8037 - val_loss: 0.5382 - val_accuracy: 0.7967\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5288 - accuracy: 0.8120 - val_loss: 0.5369 - val_accuracy: 0.8008\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5275 - accuracy: 0.8141 - val_loss: 0.5355 - val_accuracy: 0.8008\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5261 - accuracy: 0.8162 - val_loss: 0.5342 - val_accuracy: 0.8008\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5247 - accuracy: 0.8172 - val_loss: 0.5329 - val_accuracy: 0.8008\n",
      "8/8 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(tf.keras.Input(shape=(32,)))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=100, validation_data=(X_test, y_test))\n",
    "\n",
    "y_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[107,   9],\n",
       "       [ 39,  86]])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.confusion_matrix(y_test, np.round(y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[y_axis] = data[y_axis].astype('object')\n",
    "# sns.pairplot(data, hue=y_axis, vars=methods[\"SHG Intensity\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CourseWork",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "084108f72d432de2264adc3ffba650c9f1951cbab3e2483f7cb2cefcfb817813"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
